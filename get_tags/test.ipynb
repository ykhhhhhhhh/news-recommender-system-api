{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymssql\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 主函数测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2021.9.18 优化了词表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def gettags_2(text, variety):\n",
    "    word_lists = pd.read_csv('D:\\Projects\\新闻推荐\\新闻推荐接口\\get_tags\\word_lists_72_20210918.csv')\n",
    "    # word_lists = pd.read_csv('E:\\\\project\\\\djangoroot\\\\academicinfoapi\\\\get_tags\\\\word_lists_72_20210404.csv')\n",
    "    db = pymssql.connect('47.104.142.34', 'xueshu', '@WSX3edc', 'AcademicExchangePlatform', charset='cp936')\n",
    "    cursor = db.cursor()\n",
    "    # LabelSort用不到\n",
    "    sql = \"select ObjectId,LabelSort,TagName,weight,relevancy_threshold from TB_Base_Tag where IsLastStage=1 order by LabelNum desc\"\n",
    "    cursor.execute(sql)\n",
    "    wr = cursor.fetchall()  # 包含所有字段\n",
    "    objectid = np.array(wr).T[0]\n",
    "    labels = np.array(wr).T[2]\n",
    "    weights = np.array(wr).T[3].astype(np.float)  # 矩阵转置并转换为float\n",
    "    relevancy_threshold = np.array(wr).T[4].astype(np.float)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\" \", \"\")\n",
    "    text = text.replace(\"\\u3000\", \"\")\n",
    "    n = []\n",
    "    len_text = len(text)\n",
    "    unadjusted_len_text = len(text)\n",
    "    if len_text < 800:\n",
    "        pass\n",
    "    elif len_text < 1000:\n",
    "        len_text = len_text ** (39 / 40)\n",
    "    else:\n",
    "        len_text = len_text ** (14 / 15) + 211  # 211约等于1000^(39/40)-1000^(14/15)\n",
    "    words_freq = []\n",
    "    for i in range(0, word_lists.shape[1]):\n",
    "        freq = 0\n",
    "        matched_words=[]\n",
    "        for word in word_lists.iloc[:, i]:\n",
    "            if type(word) != str:\n",
    "                continue\n",
    "            if word.encode('utf-8').isalpha():  # 判断是否为纯英文，防止出现apple匹配pl的情况\n",
    "                if text.find(word) == -1:\n",
    "                    # if word in text: 慢的很\n",
    "                    words_freq.append((word, 0))  # 改进算法速度，因为re正则匹配速度比较慢,太妙了\n",
    "                else:\n",
    "                    regex = re.compile(r'[^A-Za-z](' + word + ')[^A-Za-z]')\n",
    "                    word_freq = len(regex.findall(text))\n",
    "                    if word_freq:\n",
    "                        freq += 1\n",
    "                    words_freq.append((word, word_freq))\n",
    "            else:\n",
    "                word_freq = text.count(word)\n",
    "                if word_freq != 0:\n",
    "                    freq += 1\n",
    "                    matched_words.append(word) #记录每个学科匹配的词，来优化词表\n",
    "                words_freq.append((word, word_freq)) #放在上个if里面的话，如果只有不到5个词得到匹配就会报错\n",
    "        n.append((i, freq, freq / len_text ,matched_words))  # freq/len_text\n",
    "    freq_sum = np.dot(np.array(n).T[1], weights)  # 不同学科权重不同，感兴趣的学科freq_sum会有更大的权重，更容易相关\n",
    "    k = freq_sum / unadjusted_len_text\n",
    "    r = \"相关\" if k >= 0.33 else \"不相关\"\n",
    "    # n.sort(key=lambda x: x[1], reverse=True) #各学科词表按匹配词数排序,应该按照相关性排！！！！！\n",
    "    tags = []\n",
    "    for t in n:\n",
    "        correlated_rate = t[2] / relevancy_threshold[t[0]]  # 文章标签关联度\n",
    "        if correlated_rate >= 1:  # 若比值大于阈值\n",
    "            tags.append([labels[t[0]], 100 ,t[3],len(t[3])])\n",
    "        elif correlated_rate >= 0.5:\n",
    "            tags.append([labels[t[0]], correlated_rate * 100,t[3],len(t[3])])\n",
    "        else:\n",
    "            continue\n",
    "    words_freq = list(set(words_freq))  # 去除重复值\n",
    "    words_freq.sort(key=lambda x: x[1], reverse=True)\n",
    "    keywords = words_freq[0:5]  # 此表中匹配次数前五的词\n",
    "    db.close()\n",
    "    cursor.close()\n",
    "    if variety:  # 1为普通新闻 0为会议通知\n",
    "        tags=pd.DataFrame(tags).nlargest(3,[1],keep='all').values.tolist() #返回前三高，并保留并列值\n",
    "        return r, k, tags, keywords\n",
    "    else:\n",
    "        for label_name in labels:\n",
    "            if text.find(label_name) != -1:\n",
    "                for j in range(0, len(tags)):\n",
    "                    if tags[j][0] == label_name:  # 布尔型索引,相同位置\n",
    "                        tags[j][1] = 100  # 这里如果用for tag in tags，修改tag的值不会改变tags\n",
    "                        break  # 为了提高效率break\n",
    "                else:\n",
    "                    tags.append([label_name, 100])  # for else语句 else会被break掉\n",
    "        tags=pd.DataFrame(tags).nlargest(3,[1],keep='all').values.tolist()\n",
    "        r = \"相关\"\n",
    "        return r, k, tags, keywords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\新闻推荐\\新闻推荐接口\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3361: DtypeWarning: Columns (0,7,8,9,11,12,17,18,19,21,26,27,31,33,38,44,49,50,52,55,57,58,59,62) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "d:\\projects\\新闻推荐\\新闻推荐接口\\venv\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n",
      "d:\\projects\\新闻推荐\\新闻推荐接口\\venv\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  del sys.path[0]\n",
      "d:\\projects\\新闻推荐\\新闻推荐接口\\venv\\lib\\site-packages\\ipykernel_launcher.py:50: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('相关', 0.7984375, [['精细化工', 71.42857142857143, ['生物降解', '添加剂', '水凝胶', '清洁生产', '纤维素', '蛋白质', '农业生产', '聚合物', '化学物质', '土壤污染', '化学品', '糖', '新材料', '水分', '地下水', '生物医学'], 16], ['环境化学', 62.499999999999986, ['地下水', '生物降解', '添加剂', '土壤污染', '化学物质', '纤维素', '土壤', '蛋白质', '地表水', '聚合物', '化学品', '生物聚合', '食品工业', '污染'], 14], ['高分子化学', 58.03571428571428, ['水凝胶', '纤维素', '聚合物', '生物降解', '清洁生产', '添加剂', '蛋白质', '食品工业', '糖', '土壤污染', '海藻酸', '地下水', '化学品'], 13], ['环境生态与毒理学', 58.03571428571428, ['生物降解', '地下水', '土壤污染', '化学品', '土壤', '化学物质', '蛋白质', '纤维素', '水凝胶', '添加剂', '食品工业', '藻', '污染'], 13], ['三废', 58.03571428571428, ['清洁生产', '地下水', '土壤污染', '生物降解', '化学物质', '添加剂', '蛋白质', '纤维素', '聚合物', '化学品', '水凝胶', '新材料', '污染'], 13]], [('土壤', 5), ('农业', 5), ('肥料', 3), ('水凝胶', 3), ('添加剂', 2)])\n"
     ]
    }
   ],
   "source": [
    "text='''\n",
    "新凝胶可减少土地用水并避免污染\n",
    "\n",
    "　俄罗斯托木斯克理工大学科研人员开发出一种由食物废料制成的凝胶。新材料可使农业生产中定点使用化肥和水，促进农业产业更加经济和环保。相关研究成果近日发表在《清洁生产杂志》上。\n",
    "\n",
    "　　目前，水和肥料都没有在农业中得到最佳使用，传统的植物栽培方法，使大部分水和化学物质，包括对动物有毒的化学物质，穿过土壤“溜过”根部，与地下水和地表水混合。为此，全球农业科技工作者都在寻找可以解决上述问题的新材料。俄托木斯克理工大学科研人员开发出一种聚合物水凝胶。该凝胶可作为土壤的“智能”添加剂，有助于避免土壤污染，显著减少用水量并改善植物对肥料的吸收。\n",
    "\n",
    "　　该大学化学与生物医学技术研究学院研究员安东尼奥·迪·马蒂诺说，新研发的材料能够在下雨或灌溉时储存大量水分，然后随着土壤变干缓慢释放。例如，在一些地区使用这种凝胶，可将灌溉次数减少到每周一次。他还称，新研发的水凝胶完全可以生物降解，也就是说，经过一段时间后，它们会“溶解”在土壤中，毫无踪迹。\n",
    "\n",
    "　　安东尼奥·迪·马蒂诺表示，新技术的一个关键特征是能够用农业和食品工业的有机废料生产凝胶，其主要材料是多糖和蛋白质。但科研人员也在研究纤维素、海藻酸和其他一些生物聚合物的可能性，尽量减少或完全避免使用化学品，并避免采纳需要大量能源的流程。\n",
    "\n",
    "　　据悉，新的水凝胶可用于更高效、更温和地施用肥料或其他化学品，用添加剂浸透后的成品凝胶只需简单地分置在植物根部周围就可以，其使用寿命取决于凝胶的具体成分，平均为几个星期，这种凝胶适用于大型农场和园艺业。\n",
    "'''\n",
    "print(gettags_2(text,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2021.9.19 算法改进\n",
    "当多个标签得分相同时，返回得分前三名的所有标签"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[['精细化工',\n  71.42857142857143,\n  ['生物降解',\n   '添加剂',\n   '水凝胶',\n   '清洁生产',\n   '纤维素',\n   '蛋白质',\n   '农业生产',\n   '聚合物',\n   '化学物质',\n   '土壤污染',\n   '化学品',\n   '糖',\n   '新材料',\n   '水分',\n   '地下水',\n   '生物医学'],\n  16],\n ['环境化学',\n  62.499999999999986,\n  ['地下水',\n   '生物降解',\n   '添加剂',\n   '土壤污染',\n   '化学物质',\n   '纤维素',\n   '土壤',\n   '蛋白质',\n   '地表水',\n   '聚合物',\n   '化学品',\n   '生物聚合',\n   '食品工业',\n   '污染'],\n  14],\n ['高分子化学',\n  58.03571428571428,\n  ['水凝胶',\n   '纤维素',\n   '聚合物',\n   '生物降解',\n   '清洁生产',\n   '添加剂',\n   '蛋白质',\n   '食品工业',\n   '糖',\n   '土壤污染',\n   '海藻酸',\n   '地下水',\n   '化学品'],\n  13],\n ['环境生态与毒理学',\n  58.03571428571428,\n  ['生物降解',\n   '地下水',\n   '土壤污染',\n   '化学品',\n   '土壤',\n   '化学物质',\n   '蛋白质',\n   '纤维素',\n   '水凝胶',\n   '添加剂',\n   '食品工业',\n   '藻',\n   '污染'],\n  13],\n ['三废',\n  58.03571428571428,\n  ['清洁生产',\n   '地下水',\n   '土壤污染',\n   '生物降解',\n   '化学物质',\n   '添加剂',\n   '蛋白质',\n   '纤维素',\n   '聚合物',\n   '化学品',\n   '水凝胶',\n   '新材料',\n   '污染'],\n  13]]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tttt[i] for i in pd.DataFrame(tttt).nlargest(3,[1],keep='all').index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[['精细化工',\n  71.42857142857143,\n  ['生物降解',\n   '添加剂',\n   '水凝胶',\n   '清洁生产',\n   '纤维素',\n   '蛋白质',\n   '农业生产',\n   '聚合物',\n   '化学物质',\n   '土壤污染',\n   '化学品',\n   '糖',\n   '新材料',\n   '水分',\n   '地下水',\n   '生物医学'],\n  16],\n ['环境化学',\n  62.499999999999986,\n  ['地下水',\n   '生物降解',\n   '添加剂',\n   '土壤污染',\n   '化学物质',\n   '纤维素',\n   '土壤',\n   '蛋白质',\n   '地表水',\n   '聚合物',\n   '化学品',\n   '生物聚合',\n   '食品工业',\n   '污染'],\n  14],\n ['高分子化学',\n  58.03571428571428,\n  ['水凝胶',\n   '纤维素',\n   '聚合物',\n   '生物降解',\n   '清洁生产',\n   '添加剂',\n   '蛋白质',\n   '食品工业',\n   '糖',\n   '土壤污染',\n   '海藻酸',\n   '地下水',\n   '化学品'],\n  13],\n ['环境生态与毒理学',\n  58.03571428571428,\n  ['生物降解',\n   '地下水',\n   '土壤污染',\n   '化学品',\n   '土壤',\n   '化学物质',\n   '蛋白质',\n   '纤维素',\n   '水凝胶',\n   '添加剂',\n   '食品工业',\n   '藻',\n   '污染'],\n  13],\n ['三废',\n  58.03571428571428,\n  ['清洁生产',\n   '地下水',\n   '土壤污染',\n   '生物降解',\n   '化学物质',\n   '添加剂',\n   '蛋白质',\n   '纤维素',\n   '聚合物',\n   '化学品',\n   '水凝胶',\n   '新材料',\n   '污染'],\n  13]]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tttt).nlargest(3,[1],keep='all').values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### isactivity测试\n",
    "### 正则表达式测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def isActivity(title):\n",
    "    f=open('无关通讯过滤.txt','r',encoding='utf-8')\n",
    "    lines=f.readlines()\n",
    "    for word in [i.strip('\\n') for i in lines]:\n",
    "        regex = re.compile(word)\n",
    "        if regex.search(title):\n",
    "            f.close()\n",
    "            return 1 #1为活动，国家级以下获奖类新闻\n",
    "    f.close()\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "建设\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t1 = \"四川省能源中心获四川省牛人奖\"\n",
    "p1 = \"\\S\\S{2,3}[省市州]\\S+[奖]\" \n",
    "t2=\"天大深圳学院绿色建筑与海绵城市科研中心部署今年工作\"\n",
    "p2=\"部署\\S+工作\"\n",
    "t3=\"天津大学助力河南创新驱动发展 建设中原先进技术研究院\"\n",
    "p3=\"(组建|建设)\\S+(实验室|研究院)\"\n",
    "regex = re.compile(p3)\n",
    "result=regex.search(t3)\n",
    "print(result.group(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 1\n1 1\n2 0\n3 1\n4 0\n5 1\n6 1\n7 1\n8 1\n9 0\n10 1\n11 0\n12 1\n13 1\n14 0\n15 1\n16 1\n17 1\n18 1\n19 1\n20 0\n21 1\n22 1\n23 0\n24 1\n25 1\n26 0\n27 0\n28 1\n29 1\n30 0\n31 1\n32 1\n33 1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "testdata=pd.read_excel('文章标题总结.xlsx',header=None)\n",
    "for i in testdata.iterrows():\n",
    "    print(i[0],isActivity(i[1][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 算法改进\n",
    "对于英文单词用正则表达式匹配 因为有word边界的问题"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zz='LED'\n",
    "ttt='阿克苏,LED凯撒'\n",
    "regex=re.compile(r'[^A-Za-z]('+zz+')[^A-Za-z]')\n",
    "fffffffff=regex.findall(ttt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 其他"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "value=1000\n",
    "value ** (1 / 1000)\n",
    "math.log(100,1.0046157902783952) #log函数不行，因为一开始上涨很快，斜率\n",
    "1000 ** (39/40)-(1000 ** (14/15))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#\n",
    "#tag_weight和TB_base_tag整合\n",
    "for i in range(0,72):\n",
    "    weight=float(wr[i][3])\n",
    "    relevancy_threshold=float(wr[i][4])\n",
    "    objectid=wr[i][0]\n",
    "    sql=\"update TB_Base_Tag set weight= %s,relevancy_threshold=%s where ObjectId=%s\"\n",
    "    cursor.execute(sql,(weight,relevancy_threshold,objectid))\n",
    "    db.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#老版本\n",
    "def gettags(text):\n",
    "    word_lists = pd.read_csv('D:\\Projects\\新闻推荐\\新闻推荐接口\\get_tags\\word_lists_72.csv')\n",
    "    db = pymssql.connect('47.104.142.34', 'xueshu',   '@WSX3edc', 'AcademicExchangePlatform')\n",
    "    cursor = db.cursor()\n",
    "    sql = \"select * from Tag_weight\"\n",
    "    cursor.execute(sql)\n",
    "    wr = cursor.fetchall()  # 包含所有字段\n",
    "    weights = np.array(wr).T[3].astype(np.float)  # 矩阵转置并转换为float\n",
    "    relevancy_threshold = np.array(wr).T[4].astype(np.float)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\" \", \"\")\n",
    "    text = text.replace(\"\\u3000\", \"\")\n",
    "    n = []\n",
    "    len_text = len(text)\n",
    "    words_freq = []\n",
    "    for i in range(0, word_lists.shape[1]):\n",
    "        freq = 0\n",
    "        for word in word_lists.iloc[:, i]:\n",
    "            if type(word) != str:\n",
    "                continue\n",
    "            if word.encode('utf-8').isalpha():  # 判断是否为纯英文，防止出现apple匹配pl的情况\n",
    "                regex = re.compile(r'[^A-Za-z](' + word + ')[^A-Za-z]')\n",
    "                find = regex.findall(text)\n",
    "                word_freq = len(find)\n",
    "                if find:\n",
    "                    freq += 1\n",
    "                words_freq.append((word, word_freq))\n",
    "            else:\n",
    "                word_freq = text.count(word)\n",
    "                if word_freq != 0:\n",
    "                    freq += 1\n",
    "                words_freq.append((word, word_freq))\n",
    "        n.append((i, freq, freq / len_text))  # freq/len_text\n",
    "    freq_sum = np.dot(np.array(n).T[1], weights)\n",
    "    k = freq_sum / len_text\n",
    "    r = \"相关\" if k >= 0.33 else \"不相关\"\n",
    "    n.sort(key=lambda x: x[1], reverse=True)\n",
    "    tags = []\n",
    "    for i in n[0:3]:\n",
    "        correlated_rate = i[2] / relevancy_threshold[i[0]]  # 文章标签关联度\n",
    "        if correlated_rate >= 1:  # 若比值大于阈值\n",
    "            tags.append((wr[i[0]][0], 100))\n",
    "        elif correlated_rate >= 0.5:\n",
    "            tags.append((wr[i[0]][0], correlated_rate * 100))\n",
    "        else:\n",
    "            continue\n",
    "    words_freq = list(set(words_freq))  # 去除重复值\n",
    "    words_freq.sort(key=lambda x: x[1], reverse=True)\n",
    "    keywords = words_freq[0:5]  # 此表中匹配次数前五的词\n",
    "    db.close()\n",
    "    cursor.close()\n",
    "    return r, tags, keywords\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}